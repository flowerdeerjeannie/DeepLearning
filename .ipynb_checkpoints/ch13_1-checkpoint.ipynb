{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76245b48-a213-40c9-b2fe-56d6d6aa4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68b3539-3712-467c-bcd0-a8ab4f86c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:04<00:00, 1995725.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 148062.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:01<00:00, 988987.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 4547750.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data/MNIST\", train=True, transform=transform, download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root=\"./data/MNIST\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=False) #num_workers= GPU 갯수\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac36d689-12ad-443b-90f1-25b7976f98be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim, fc2_input_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_cnn = nn.Sequential( nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "                                          nn.ReLU(True),\n",
    "                                          nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "                                          nn.BatchNorm2d(16),\n",
    "                                          nn.ReLU(True),\n",
    "                                          nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "                                          nn.ReLU(True))\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.encoder_lin = nn.Sequential(nn.Linear( 3* 3* 32, 128),\n",
    "                                         nn.ReLU(True),\n",
    "                                         nn.Linear(128, encoded_space_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a454b2-03d3-41d9-b7dd-59e234a466b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim, fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential( nn.Linear(encoded_space_dim, 128),\n",
    "                                          nn.ReLU(True),\n",
    "                                          nn.Linear(128, 3* 3* 32),\n",
    "                                          nn.ReLU(True))\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "                                      unflattened_size=(32, 3, 3))\n",
    "        self.decoder_conv = nn.Sequential( nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
    "                                           nn.BatchNorm2d(16),\n",
    "                                           nn.ReLU(True),\n",
    "                                           nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "                                           nn.BatchNorm2d(8),\n",
    "                                           nn.ReLU(True),\n",
    "                                           nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a68f7a-9eb6-44e4-8402-11638fd66ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(encoded_space_dim=4, fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=4, fc2_input_dim=128)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "params_to_optimize = [ #인코더와 디코더에서 사용할 파라미터를 다르게 지정\n",
    "    {'params':encoder.parameters()},\n",
    "    {'params':decoder.parameters()}\n",
    "]\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=0.001, weight_decay=1e-05)\n",
    "loss_fn=torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9502ce9-0a9f-419e-b451-a850d92c1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer, noise_factor=0.3):\n",
    "    encoder.train() #학습입니다\n",
    "    decoder.train() \n",
    "    train_loss=[]\n",
    "    \n",
    "    for image_batch, _ in dataloader: #비지도 학습이므로 y_label 필요 없음\n",
    "        image_noisy = add_noise(image_batch, noise_factor) #멀쩡한 이미지에 노이즈 더하기\n",
    "        image_noisy = image_noisy.to(device)\n",
    "        encoded_data = encoder(image_noisy) #노이즈가 들어간 이미지를 인코더에 넣어서 벡터 출력\n",
    "        decoded_data = decoder(encoded_data) #그 벡터를 디코더에 입력하여 노이즈가 제거된 이미지 생성\n",
    "        loss = loss_fn(decoded_data, image_noisy) #노이즈 이미지와 노이즈 제거 이미지 사이의 값을 측정함\n",
    "        #왜냐하면 decoder는 노이즈 잘 제거하는게 목적이므로\n",
    "        #디코더의 성능을 평가하기 위해 loss_fn에 위 두개가 들어감\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ace714-5136-4fa6-b8fe-8bda9935db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(encoder, decoder, device, dataloader, loss_fn, noise_factor=0.3):\n",
    "    encoder.eval() #평가입니다\n",
    "    decoder.eval()\n",
    "\n",
    "    #테스트 과정에서는 모델 성능 평가 위해서 \n",
    "    #모델의 출력(복원된 이미지) 와, 원본 이미지 를 비교함. 이걸 기억해야함\n",
    "\n",
    "    \n",
    "    with torch.no_grad(): #메모리사용줄이기\n",
    "        conc_out = [] #디코더가 생성해낸 복원된 이미지. 평가 대상\n",
    "        conc_label = [] #노이즈도 없고 건드려지지않은 깨끗한 이미지. 정답. 비교 대상\n",
    "        for image_batch, _ in dataloader:\n",
    "            image_batch = image_batch.to(device)\n",
    "            encoded_data = encoder(image_batch) #입력 이미지 인코딩 \n",
    "            decoded_data = decoder(encoded_data)\n",
    "            conc_out.append(decoded_data.cpu()) #디코더의 출력을 리스트에 저장함\n",
    "            conc_label.append(image_batch.cpu()) #입력 이미지를 저장함\n",
    "        conc_out = torch.cat(conc_out) #리스트 형식으로 저장된 모든 값을 하나의 텐서로 결합\n",
    "        conc_label = torch.cat(conc_label) # 리스트 형식으로 저장된 모든 레이블을 하나의 텐서로 결합\n",
    "        val_loss = loss_fn(conc_out, conc_label)  # 디코더의 출력과 입력 이미지 사이의 손실을 계산\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60e42b1-af65-4f0d-89ef-f2fb9b2c0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(inputs, noise_factor=0.3):\n",
    "    noisy = inputs + torch.randn_like(inputs) * noise_factor #inputs과 동일한 크기의 노이즈 텐서 생성\n",
    "    noisy = torch.clip(noisy, 0., 1.) #clip(값의 범위를 조정할 데이터셋, 최솟값, 최댓값)\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64563d73-bcb6-4353-9cbe-5b6d4141983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"]='Malgun Gothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e309f6e7-bd5d-4e34-b3c2-d768148ba44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(encoder, decoder, n=5, noise_factor=0.3):\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i+1)\n",
    "        img = test_dataset[i][0].unsqueeze(0)\n",
    "        image_noisy = add_noise(img, noise_factor)\n",
    "        image_noisy = image_noisy.to(device)\n",
    "\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            rec_img = decoder(encoder(image_noisy))\n",
    "\n",
    "        plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n//2:\n",
    "            ax.set_title(\"원래 이미지\")\n",
    "        ax = plt.subplot(3, n, i+1+n)\n",
    "        plt.imshow(image_noisy.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n//2:\n",
    "            ax.set_title(\"노이즈가 적용되어 손상된 이미지\")\n",
    "\n",
    "        ax = plt.subplot(3, n, i+1+n+n)\n",
    "        plt.imshow(rec_img.squeeze().numpy(), cmap='gist_gray')        \n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n//2:\n",
    "            ax.set_title(\"재구성된 이미지\")\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1,\n",
    "                        right=0.7,\n",
    "                        top=0.9,\n",
    "                        wspace=0.3,\n",
    "                        hspace=0.3)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd39f9-7da1-4492-994b-aeed5c71b09d",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c57ea-a9af-4c57-aac8-dde3e5c9bfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/30\n",
      "\n",
      " EPOCH 1/30 \t train loss 0.076 \t val loss 0.057\n",
      "EPOCH 2/30\n",
      "\n",
      " EPOCH 2/30 \t train loss 0.060 \t val loss 0.050\n",
      "EPOCH 3/30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_epochs = 30\n",
    "history_da = {'train_loss':[], 'val_loss':[]}\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH %d/%d' % (epoch+1, num_epochs))\n",
    "    train_loss=train_epoch( #아까 만들어둔 train_epoch 함수에 파라미터 부여함\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        device=device,\n",
    "        dataloader=train_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim, noise_factor=0.3) #출력은 mean으로 훈련데이터의 평균 손실값 \n",
    "    val_loss=test_epoch(\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        device=device,\n",
    "        dataloader=test_loader,\n",
    "        loss_fn=loss_fn, noise_factor=0.3)\n",
    "    history_da['train_loss'].append(train_loss)\n",
    "    history_da['val_loss'].append(val_loss)\n",
    "    print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch+1, num_epochs, train_loss, val_loss))\n",
    "plot_ae_outputs(encoder, decoder, noise_factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ccd63e-312c-407d-9298-17e41a36caf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
