{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff792bb-e682-41bb-b53d-ef7d398dee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e43fe2-965d-43b6-9e24-d6f4910ffcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.features = nn.Sequential(nn.Conv2d(1, 6, 5, 1, padding='same'),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2),\n",
    "                                    nn.Conv2d(6, 16, 5, 1, padding='same'),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2),\n",
    "                                    nn.Conv2d(16, 126, 5, 1, padding='same'),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(1134 ,128),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(128, 64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(64, 10),\n",
    "                                       nn.Softmax(dim=1))\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # [batch_size, 126, 3, 3]\n",
    "        print(f'Features output shape: {x.shape}')  # Debug: check features output shape\n",
    "        x = self.flatten(x)   # [batch_size, 1134]\n",
    "        print(f'Flattened shape: {x.shape}')        # Debug: check flattened shape\n",
    "        x = self.classifier(x) # [batch_size, 10]\n",
    "        print(f'Classifier output shape: {x.shape}')  # Debug: check classifier output shape\n",
    "        return x\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e44224e-f797-49f3-92fb-dbae5eb749e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(16, 126, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1134, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (5): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91df3cb3-2766-47c2-b4df-0ecb959f474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed56e29-ce99-4173-b94c-6aa3d0fde47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb626537-ba90-4d4a-8f32-289c40a51632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST('data', download=True, transform=v2.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad406acc-5977-4cf1-a6f2-96cbe592fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ca32c87-aa37-48e2-98ab-59fbb230a366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_label in data_loader:\n",
    "    print(X_train.shape, y_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceaab9c6-3f0b-4854-a1fb-98c1b92b8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features output shape: torch.Size([32, 126, 3, 3])\n",
      "Flattened shape: torch.Size([32, 1134])\n",
      "Classifier output shape: torch.Size([32, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0965, 0.1119, 0.0861, 0.0994, 0.1042, 0.1091, 0.1024, 0.0958, 0.0972,\n",
       "         0.0973],\n",
       "        [0.0965, 0.1119, 0.0863, 0.0994, 0.1040, 0.1091, 0.1023, 0.0958, 0.0972,\n",
       "         0.0974],\n",
       "        [0.0966, 0.1119, 0.0861, 0.0994, 0.1042, 0.1093, 0.1022, 0.0957, 0.0973,\n",
       "         0.0972],\n",
       "        [0.0965, 0.1120, 0.0859, 0.0994, 0.1042, 0.1093, 0.1023, 0.0959, 0.0971,\n",
       "         0.0975],\n",
       "        [0.0966, 0.1118, 0.0861, 0.0995, 0.1042, 0.1093, 0.1022, 0.0958, 0.0972,\n",
       "         0.0973],\n",
       "        [0.0966, 0.1119, 0.0860, 0.0995, 0.1043, 0.1092, 0.1023, 0.0958, 0.0971,\n",
       "         0.0973],\n",
       "        [0.0966, 0.1120, 0.0861, 0.0995, 0.1041, 0.1095, 0.1022, 0.0957, 0.0972,\n",
       "         0.0972],\n",
       "        [0.0965, 0.1118, 0.0862, 0.0995, 0.1041, 0.1092, 0.1023, 0.0958, 0.0973,\n",
       "         0.0974],\n",
       "        [0.0966, 0.1119, 0.0861, 0.0995, 0.1041, 0.1095, 0.1022, 0.0957, 0.0972,\n",
       "         0.0972],\n",
       "        [0.0964, 0.1121, 0.0861, 0.0996, 0.1041, 0.1093, 0.1022, 0.0958, 0.0971,\n",
       "         0.0973],\n",
       "        [0.0965, 0.1120, 0.0862, 0.0996, 0.1041, 0.1093, 0.1022, 0.0957, 0.0971,\n",
       "         0.0974],\n",
       "        [0.0966, 0.1120, 0.0861, 0.0995, 0.1041, 0.1093, 0.1023, 0.0959, 0.0970,\n",
       "         0.0972],\n",
       "        [0.0967, 0.1119, 0.0863, 0.0995, 0.1041, 0.1092, 0.1023, 0.0957, 0.0973,\n",
       "         0.0971],\n",
       "        [0.0967, 0.1120, 0.0862, 0.0995, 0.1042, 0.1091, 0.1023, 0.0958, 0.0971,\n",
       "         0.0972],\n",
       "        [0.0965, 0.1119, 0.0861, 0.0995, 0.1042, 0.1095, 0.1022, 0.0957, 0.0971,\n",
       "         0.0973],\n",
       "        [0.0965, 0.1119, 0.0860, 0.0994, 0.1042, 0.1093, 0.1024, 0.0958, 0.0973,\n",
       "         0.0974],\n",
       "        [0.0964, 0.1120, 0.0862, 0.0994, 0.1043, 0.1093, 0.1023, 0.0957, 0.0972,\n",
       "         0.0973],\n",
       "        [0.0966, 0.1118, 0.0861, 0.0995, 0.1040, 0.1091, 0.1025, 0.0958, 0.0973,\n",
       "         0.0973],\n",
       "        [0.0966, 0.1120, 0.0861, 0.0994, 0.1042, 0.1094, 0.1022, 0.0958, 0.0971,\n",
       "         0.0973],\n",
       "        [0.0967, 0.1119, 0.0860, 0.0995, 0.1041, 0.1093, 0.1023, 0.0957, 0.0972,\n",
       "         0.0974],\n",
       "        [0.0968, 0.1118, 0.0862, 0.0994, 0.1042, 0.1093, 0.1022, 0.0956, 0.0973,\n",
       "         0.0972],\n",
       "        [0.0964, 0.1120, 0.0862, 0.0994, 0.1042, 0.1093, 0.1024, 0.0958, 0.0971,\n",
       "         0.0972],\n",
       "        [0.0965, 0.1119, 0.0861, 0.0995, 0.1042, 0.1092, 0.1023, 0.0958, 0.0971,\n",
       "         0.0974],\n",
       "        [0.0965, 0.1120, 0.0860, 0.0994, 0.1041, 0.1093, 0.1023, 0.0959, 0.0971,\n",
       "         0.0975],\n",
       "        [0.0966, 0.1119, 0.0860, 0.0994, 0.1042, 0.1093, 0.1023, 0.0958, 0.0971,\n",
       "         0.0973],\n",
       "        [0.0966, 0.1119, 0.0861, 0.0994, 0.1041, 0.1092, 0.1023, 0.0958, 0.0973,\n",
       "         0.0974],\n",
       "        [0.0966, 0.1118, 0.0860, 0.0995, 0.1041, 0.1094, 0.1021, 0.0958, 0.0972,\n",
       "         0.0974],\n",
       "        [0.0965, 0.1120, 0.0862, 0.0995, 0.1040, 0.1092, 0.1023, 0.0958, 0.0972,\n",
       "         0.0973],\n",
       "        [0.0964, 0.1119, 0.0861, 0.0995, 0.1040, 0.1094, 0.1023, 0.0958, 0.0972,\n",
       "         0.0973],\n",
       "        [0.0965, 0.1120, 0.0860, 0.0995, 0.1040, 0.1093, 0.1023, 0.0959, 0.0972,\n",
       "         0.0974],\n",
       "        [0.0966, 0.1120, 0.0862, 0.0995, 0.1042, 0.1093, 0.1022, 0.0957, 0.0972,\n",
       "         0.0972],\n",
       "        [0.0964, 0.1120, 0.0862, 0.0995, 0.1041, 0.1093, 0.1024, 0.0958, 0.0971,\n",
       "         0.0973]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83ddb73-8eb9-4697-96a3-84f66cdb0614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features output shape: torch.Size([32, 126, 3, 3])\n",
      "Flattened shape: torch.Size([32, 1134])\n",
      "Classifier output shape: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_label in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(X_train)\n",
    "        loss_fn = loss(outputs, y_label)\n",
    "        loss_fn.backward()\n",
    "        optimizer.step()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3727716a-3f1b-451d-bb30-cbcd71123421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features output shape: torch.Size([32, 126, 3, 3])\n",
      "Flattened shape: torch.Size([32, 1134])\n",
      "Classifier output shape: torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "input_tensor = torch.randn(32, 1, 28, 28)  # [batch_size, channels, height, width]\n",
    "output = model(input_tensor)\n",
    "print(output.shape) \n",
    " # Should be [batch_size, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e37ded-76a6-41a0-9046-5d2a4d243f3d",
   "metadata": {},
   "source": [
    "### Alexnet 불러오고 내 커스텀에 맞게 조정해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "721e9411-e0cd-4213-9b11-4a3146e31a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet, AlexNet_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8da6d785-f1b8-42e9-b545-515e15bd250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02de573c-a6d4-4056-93c6-2e14e831d851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (7): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#원래 알렉스넷의 클래스는 1000개여서 우리 개고양이에 적합하게 2개로 고치는 법\n",
    "#모델 자체를 건들지 않고 마지막 classifier 부분만 조정!\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 2),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6556b7f3-a47e-4c29-90c4-f6485344038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-summary\n",
      "  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\n",
      "Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: torch-summary\n",
      "Successfully installed torch-summary-1.4.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8dead2ec-6e49-465e-a7f6-ab071bfd776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#내가 생성한 모델의 모든 파라미터를 False로 설정 = 실행안되게.\n",
    "\n",
    "#for p in model.parameters():\n",
    "#    p.requires_grad = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966642db-b193-4577-8879-78aa6314af72",
   "metadata": {},
   "source": [
    "### from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33665903-0e7e-46a4-91ee-7c5dba000c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          23,296\n",
      "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         307,392\n",
      "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         663,936\n",
      "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         884,992\n",
      "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         590,080\n",
      "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
      "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
      "├─Sequential: 1-3                        [-1, 2]                   --\n",
      "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
      "|    └─Linear: 2-15                      [-1, 512]                 4,719,104\n",
      "|    └─ReLU: 2-16                        [-1, 512]                 --\n",
      "|    └─Dropout: 2-17                     [-1, 512]                 --\n",
      "|    └─Linear: 2-18                      [-1, 64]                  32,832\n",
      "|    └─ReLU: 2-19                        [-1, 64]                  --\n",
      "|    └─Linear: 2-20                      [-1, 2]                   130\n",
      "|    └─Softmax: 2-21                     [-1, 2]                   --\n",
      "==========================================================================================\n",
      "Total params: 7,221,762\n",
      "Trainable params: 7,221,762\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 667.54\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3.70\n",
      "Params size (MB): 27.55\n",
      "Estimated Total Size (MB): 31.83\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          23,296\n",
       "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
       "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         307,392\n",
       "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
       "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
       "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         663,936\n",
       "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
       "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         884,992\n",
       "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         590,080\n",
       "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
       "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
       "├─Sequential: 1-3                        [-1, 2]                   --\n",
       "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
       "|    └─Linear: 2-15                      [-1, 512]                 4,719,104\n",
       "|    └─ReLU: 2-16                        [-1, 512]                 --\n",
       "|    └─Dropout: 2-17                     [-1, 512]                 --\n",
       "|    └─Linear: 2-18                      [-1, 64]                  32,832\n",
       "|    └─ReLU: 2-19                        [-1, 64]                  --\n",
       "|    └─Linear: 2-20                      [-1, 2]                   130\n",
       "|    └─Softmax: 2-21                     [-1, 2]                   --\n",
       "==========================================================================================\n",
       "Total params: 7,221,762\n",
       "Trainable params: 7,221,762\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 667.54\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 3.70\n",
       "Params size (MB): 27.55\n",
       "Estimated Total Size (MB): 31.83\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "#모델, 이미지사이즈\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35b040e0-cb43-42fd-b7b6-fe005c9d76c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.rand(32, 3, 224, 224)\n",
    "model(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79718024-a9e3-4047-8c15-8ccf2f14f5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 3, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 64, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 128, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 128, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([4096, 25088]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([4096]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([4096, 4096]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([4096]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1000, 4096]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1000]) True\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): #모델의 모든 파라미터를 순회하면서\n",
    "    print(type(p), p.shape, p.requires_grad) #내가 말하는 속성을 출력하여라. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9eea187-dc4b-4388-aa4f-cd8ef77e260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder \n",
    "import torchvision.transforms.v2 as v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58c0ca3a-4b53-41c4-b26e-e7f82b293759",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transform = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToTensor()\n",
    "])\n",
    "\n",
    "root = './080289/chap06/data/dogs-vs-cats'\n",
    "dataset=ImageFolder(root, transform=my_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0209c525-cf33-4940-8d21-8db700504f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4ebb553-125e-4545-adf4-a448b3570791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "data_loader=DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "for X_train, y_label in data_loader:\n",
    "    print(X_train.shape, y_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5806bf4-9671-4ccd-8647-73b3e37968b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b14610ba-0435-48e6-b3ca-dc81c4e7d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e38cddb4-51c6-41b3-af55-e358db4622cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d2bcda3-6a08-48f2-a6ec-0d54673153f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#돌리기 함수생성\n",
    "\n",
    "def fit(model, data_loader, loss_fn, optimizer, epochs):\n",
    "    for _ in range(epochs):\n",
    "        for X_train, y_label in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = loss_fn(outputs, y_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fdf89850-39df-4ef4-b29a-31f7fb20e609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (7): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, data_loader, loss_fn, optimizer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da45f8-bb9d-4c84-9102-2bb919881bd1",
   "metadata": {},
   "source": [
    "### VGG 모델 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4edfc43-cfc3-4fe1-a008-c5f93adbcd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16, VGG16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "512e9e23-4fe4-4edf-a676-c8596e8c42bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b2172321-6f78-49bd-8e9c-567e62ed76b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=2048, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=64, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 2048), #선형으로 표현해보고\n",
    "            nn.ReLU(inplace=True), #비선형 부분도 있을 수 있으니까 비선형(곡선)도 학습시키게 하고\n",
    "            nn.Dropout(), #과대적합 오면 안되니까 랜덤리하게 과적합방지 장치 \n",
    "            nn.Linear(2048, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a505e1db-478a-4192-be65-b7b3a4a39396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 3, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 64, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 128, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 128, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048, 25088]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 2048]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2, 64]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2]) True\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): #모델의 모든 파라미터를 순회하면서\n",
    "    #p.requires_grad = False\n",
    "    print(type(p), p.shape, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0db4026e-0b00-4009-9b07-e702f0fec1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 7, 7]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 224, 224]        1,792\n",
      "|    └─ReLU: 2-2                         [-1, 64, 224, 224]        --\n",
      "|    └─Conv2d: 2-3                       [-1, 64, 224, 224]        36,928\n",
      "|    └─ReLU: 2-4                         [-1, 64, 224, 224]        --\n",
      "|    └─MaxPool2d: 2-5                    [-1, 64, 112, 112]        --\n",
      "|    └─Conv2d: 2-6                       [-1, 128, 112, 112]       73,856\n",
      "|    └─ReLU: 2-7                         [-1, 128, 112, 112]       --\n",
      "|    └─Conv2d: 2-8                       [-1, 128, 112, 112]       147,584\n",
      "|    └─ReLU: 2-9                         [-1, 128, 112, 112]       --\n",
      "|    └─MaxPool2d: 2-10                   [-1, 128, 56, 56]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 56, 56]         295,168\n",
      "|    └─ReLU: 2-12                        [-1, 256, 56, 56]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 256, 56, 56]         590,080\n",
      "|    └─ReLU: 2-14                        [-1, 256, 56, 56]         --\n",
      "|    └─Conv2d: 2-15                      [-1, 256, 56, 56]         590,080\n",
      "|    └─ReLU: 2-16                        [-1, 256, 56, 56]         --\n",
      "|    └─MaxPool2d: 2-17                   [-1, 256, 28, 28]         --\n",
      "|    └─Conv2d: 2-18                      [-1, 512, 28, 28]         1,180,160\n",
      "|    └─ReLU: 2-19                        [-1, 512, 28, 28]         --\n",
      "|    └─Conv2d: 2-20                      [-1, 512, 28, 28]         2,359,808\n",
      "|    └─ReLU: 2-21                        [-1, 512, 28, 28]         --\n",
      "|    └─Conv2d: 2-22                      [-1, 512, 28, 28]         2,359,808\n",
      "|    └─ReLU: 2-23                        [-1, 512, 28, 28]         --\n",
      "|    └─MaxPool2d: 2-24                   [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-25                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-26                        [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-27                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-28                        [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-29                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-30                        [-1, 512, 14, 14]         --\n",
      "|    └─MaxPool2d: 2-31                   [-1, 512, 7, 7]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 512, 7, 7]           --\n",
      "├─Sequential: 1-3                        [-1, 2]                   --\n",
      "|    └─Linear: 2-32                      [-1, 2048]                51,382,272\n",
      "|    └─ReLU: 2-33                        [-1, 2048]                --\n",
      "|    └─Dropout: 2-34                     [-1, 2048]                --\n",
      "|    └─Linear: 2-35                      [-1, 64]                  131,136\n",
      "|    └─ReLU: 2-36                        [-1, 64]                  --\n",
      "|    └─Dropout: 2-37                     [-1, 64]                  --\n",
      "|    └─Linear: 2-38                      [-1, 2]                   130\n",
      "==========================================================================================\n",
      "Total params: 66,228,226\n",
      "Trainable params: 66,228,226\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 15.46\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 103.38\n",
      "Params size (MB): 252.64\n",
      "Estimated Total Size (MB): 356.59\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 512, 7, 7]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 224, 224]        1,792\n",
       "|    └─ReLU: 2-2                         [-1, 64, 224, 224]        --\n",
       "|    └─Conv2d: 2-3                       [-1, 64, 224, 224]        36,928\n",
       "|    └─ReLU: 2-4                         [-1, 64, 224, 224]        --\n",
       "|    └─MaxPool2d: 2-5                    [-1, 64, 112, 112]        --\n",
       "|    └─Conv2d: 2-6                       [-1, 128, 112, 112]       73,856\n",
       "|    └─ReLU: 2-7                         [-1, 128, 112, 112]       --\n",
       "|    └─Conv2d: 2-8                       [-1, 128, 112, 112]       147,584\n",
       "|    └─ReLU: 2-9                         [-1, 128, 112, 112]       --\n",
       "|    └─MaxPool2d: 2-10                   [-1, 128, 56, 56]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 56, 56]         295,168\n",
       "|    └─ReLU: 2-12                        [-1, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 256, 56, 56]         590,080\n",
       "|    └─ReLU: 2-14                        [-1, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-15                      [-1, 256, 56, 56]         590,080\n",
       "|    └─ReLU: 2-16                        [-1, 256, 56, 56]         --\n",
       "|    └─MaxPool2d: 2-17                   [-1, 256, 28, 28]         --\n",
       "|    └─Conv2d: 2-18                      [-1, 512, 28, 28]         1,180,160\n",
       "|    └─ReLU: 2-19                        [-1, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-20                      [-1, 512, 28, 28]         2,359,808\n",
       "|    └─ReLU: 2-21                        [-1, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-22                      [-1, 512, 28, 28]         2,359,808\n",
       "|    └─ReLU: 2-23                        [-1, 512, 28, 28]         --\n",
       "|    └─MaxPool2d: 2-24                   [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-25                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-26                        [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-27                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-28                        [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-29                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-30                        [-1, 512, 14, 14]         --\n",
       "|    └─MaxPool2d: 2-31                   [-1, 512, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 512, 7, 7]           --\n",
       "├─Sequential: 1-3                        [-1, 2]                   --\n",
       "|    └─Linear: 2-32                      [-1, 2048]                51,382,272\n",
       "|    └─ReLU: 2-33                        [-1, 2048]                --\n",
       "|    └─Dropout: 2-34                     [-1, 2048]                --\n",
       "|    └─Linear: 2-35                      [-1, 64]                  131,136\n",
       "|    └─ReLU: 2-36                        [-1, 64]                  --\n",
       "|    └─Dropout: 2-37                     [-1, 64]                  --\n",
       "|    └─Linear: 2-38                      [-1, 2]                   130\n",
       "==========================================================================================\n",
       "Total params: 66,228,226\n",
       "Trainable params: 66,228,226\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.46\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 103.38\n",
       "Params size (MB): 252.64\n",
       "Estimated Total Size (MB): 356.59\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d7370-0059-498d-9ef3-d51bf1bfa50d",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b60e9ba-6cb3-436b-8805-ceb87f0cc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e0be047-b3fb-4e44-9d87-3eef7b4db762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b0598b70-9648-42fd-9e97-74ad6fbbfa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 3, 7, 7]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 64, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 64, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 64, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 64, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 128, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 128, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 512, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 128, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 128, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 512, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 128, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 128, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 512, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 128, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 128, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 512, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 512, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 1024, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 1024, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 1024, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 1024, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 1024, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 256, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 1024, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048, 512, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048, 1024, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 2048, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048, 512, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 2048, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 3, 3]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048, 512, 1, 1]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2048]) False\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 2048]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1024]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 1024]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([103, 512]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([103]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2, 103]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2]) True\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    #p.requires_grad = False #모델 건드리기 전 - 특정 레이어만 재학습시키려면 나머지 레이어의 파라미터를 사용하지 않도록 고정해야함\n",
    "    print(type(p), p.shape, p.requires_grad) #모델 건드린 후 - 내가 변경한게 true로 유효한지 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "368089bc-a87b-4df6-b39a-1e576f5b10ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "                    nn.Linear(2048, 1024),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(512, 103),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(103, 2),\n",
    "                    nn.Softmax(dim=1)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "caf9f8a7-cac2-4172-ac2a-65f082be6ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "my_transform = v2.Compose([\n",
    "                    v2.Resize(size=(224,224)),\n",
    "                    v2.ToTensor()\n",
    "])\n",
    "dataset = ImageFolder('./080289/chap06/data/dogs-vs-cats', transform=my_transform)\n",
    "\n",
    "#데이터셋 불러온거 자체에서 사이즈를 지정해서 학습 0.8과 검증0.2로 나누기로 함\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "#숫자지정한걸로 섞음 \n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2ed1fe5f-5ebe-4a89-8fba-e4e4731d556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, int)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = dataset[0]\n",
    "type(image), type(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc61e674-960e-49c5-a00a-a44230269dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(image.shape) #배치 사이즈 없어서 채널, 크기크기만 잇는 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "50570eb8-df98-4967-9cae-d03909e06ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "755f14e9-4141-4a2d-b029-bbdbd06db1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#각각을 배치사이즈로 다르게 나누어줌.\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2688f0f9-afbe-4456-b3d6-2ec68d7252b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_label in train_loader:\n",
    "    print(X_train.shape, y_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7bd1c285-d119-42ce-92c4-078d1676b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_label in val_loader:\n",
    "    print(X_train.shape, y_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "797e37ee-ed8d-4a23-815c-d0c561cede4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\torch-book\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\envs\\torch-book\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\anaconda3\\envs\\torch-book\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\envs\\torch-book\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\torch-book\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb501b7a-d7fd-4e92-8668-0a05ac109bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3b2d73c1-fbae-4e40-a0e8-9c6ae9c15279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, loss_fn, optimizer, epochs):\n",
    "    for _ in range(epochs):\n",
    "        for X_train, y_label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = loss_fn(outputs, y_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0acc3245-7daf-4035-91c3-b335afaadf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf71418-575c-4e28-8b98-1fd39eaf65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds = [] #예측값\n",
    "    all_labels = [] #정답값\n",
    "\n",
    "    with torch.no_grad(): #평가시에는 grad 계산이 필요 없으므로. \n",
    "        for X_test, y_labels in val_loader:\n",
    "            outputs = model(X_test)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_labels.cpu().numpy())\n",
    "\n",
    "    # 정확도, Precision, Recall, F1 Score 계산\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels)) \n",
    "    #불리언- 모델의 예측한것들 중에서 정답값이 일치하는지, 양성이든 음성이든.\n",
    "    #true false라는 0또는 1로 나오므로 양음성 관계없이 mean 하면 정답맞춘 확률이 나옴\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    #양성예측도-예측값과 정답값을 비교하여 양성예측중 실제양성 비율 \n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    #실제 양성 중 모델이 바르게 예측한 비율 \n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    #precision과 recall의 균형 평가. \n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14119879-1047-4a4f-bc7f-340f7fc41f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit(model, train_loader, loss_fn, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee50f16-6e2d-43db-8d5c-4fe8b2c7fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1=evaluate_model(model, val_loader)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a912a6-becf-48c5-9da5-14b0376a3555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
