{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa1d43d-7dcc-441e-872a-78275236b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4886ae65-ae73-4556-903a-1fcbac35745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0c64726-5db1-4125-81f2-73526c69e6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 253 entries, 2019-12-11 to 2020-12-10\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       253 non-null    float64\n",
      " 1   High       253 non-null    float64\n",
      " 2   Low        253 non-null    float64\n",
      " 3   Close      253 non-null    float64\n",
      " 4   Adj Close  253 non-null    float64\n",
      " 5   Volume     253 non-null    float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 13.8 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/SBUX.csv\", index_col=[\"Date\"], date_format=\"%Y-%m-%d\") #날짜 안쓸거라서 그냥 index로 보내버림\n",
    "data[\"Volume\"]=data[\"Volume\"].astype(float) #int라서 다른애들처럼 float로 맞춰줌\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9948aa98-d335-4f33-8f49-a4643b3d813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close\n",
      "Date                                                                  \n",
      "2019-12-11   86.260002   86.870003   85.849998   86.589996   84.145752\n",
      "2019-12-12   88.000000   88.889999   87.540001   88.209999   85.720032\n",
      "2019-12-13   88.019997   88.790001   87.580002   88.669998   86.167046\n",
      "2019-12-16   89.139999   89.300003   88.430000   88.779999   86.273941\n",
      "2019-12-17   88.870003   88.970001   87.470001   88.129997   85.642288\n",
      "...                ...         ...         ...         ...         ...\n",
      "2020-12-04  101.349998  102.940002  101.070000  102.279999  101.442787\n",
      "2020-12-07  102.010002  102.220001  100.690002  101.410004  100.579918\n",
      "2020-12-08  100.370003  101.570000  100.010002  101.209999  100.381554\n",
      "2020-12-09  101.940002  102.209999  100.099998  100.400002   99.578186\n",
      "2020-12-10  103.510002  106.089996  102.750000  105.389999  104.527336\n",
      "\n",
      "[253 rows x 5 columns]                 Volume\n",
      "Date                  \n",
      "2019-12-11   4921900.0\n",
      "2019-12-12  10282100.0\n",
      "2019-12-13   6714100.0\n",
      "2019-12-16   6705600.0\n",
      "2019-12-17   7296900.0\n",
      "...                ...\n",
      "2020-12-04   6952700.0\n",
      "2020-12-07   4514800.0\n",
      "2020-12-08   3911300.0\n",
      "2020-12-09   6629900.0\n",
      "2020-12-10  12939200.0\n",
      "\n",
      "[253 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, 5:6] #5:6이니까 인덱스가 5인 열만 인덱싱 해온다. \n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51a618c0-35ea-4396-9c3b-30307a8ed5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss=ss.fit_transform(X)\n",
    "y_ms=ms.fit_transform(y)\n",
    "\n",
    "X_train = X_ss[:200, :]\n",
    "X_test = X_ss[200:, :]\n",
    "\n",
    "y_train = y_ms[:200, :]\n",
    "y_test = y_ms[200:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddc5ef51-99bf-4909-a985-ffb12eb73ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 5) (53, 5) (200, 1) (53, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffdcb50-3175-4e56-b240-e03bbb3dde3a",
   "metadata": {},
   "source": [
    "### pytorch 로 변경\n",
    "\n",
    "* 데이터를 텐서로 변경\n",
    "* 모델 설계\n",
    "* 모델 생성 후 학습, 예측, 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e4c497d-38a4-48e6-bca3-4d901bcc438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03acad64-9931-46e7-836c-9c465a8277db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 5]) torch.Size([200, 5])\n"
     ]
    }
   ],
   "source": [
    "#주의\n",
    "\n",
    "X_train_tensors_f=torch.reshape(X_train_tensors, (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_test_tensors_f=torch.reshape(X_test_tensors, (X_test_tensors.shape[0], 1, X_test_tensors.shape[1]))\n",
    "print(X_train_tensors.shape, X_train_tensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f3488-3496-4072-8136-ea18869276e3",
   "metadata": {},
   "source": [
    "### model 작성\n",
    "\n",
    "* 생성자 작성 시 : 그 모델 작성 위해서 내가 써야 하는 parameters (torch models document 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ccd5075-7ae7-44f1-b916-73eb441873a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        #num_classes - 아웃풋 갯수, input_size - column 몇개? hidden_size= 단기기억메모리 즉 은닉층 몇개? num_layers = 한층짜리레이어 몇개?\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "                input_size = input_size,\n",
    "                hidden_size = hidden_size,\n",
    "                num_layers = num_layers,\n",
    "                batch_first=True) #batch_first-나온 텐서의 시퀸스 바꾸는 옵션\n",
    "        \n",
    "                            #맨끝부분이 hidden_size라는거 알자나\n",
    "        self.fc_1=nn.Linear(hidden_size, 128)\n",
    "        self.fc=nn.Linear(128, num_classes)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, x): #hidden_state.shape 했을때 torch.Size([1, 3, 20] 에서 근거\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #h_0:히든레이어에 들어가는 초기값 \n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #순서를 지켜서 사용할 것.\n",
    "        hn = hn.view(-1, self.hidden_size) #view는 원본데이터 손상없이 읽기전용. -1은 reshape 니알아서, 대신 맨끝은 hidden_size\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b58ce9bd-8e60-4a14-8471-db827da79232",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "input_size = 5\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "\n",
    "model = LSTM(num_classes, input_size, hidden_size, num_layers, X_train_tensors_f.shape[1])\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#손실 함수의 기울기를 최소화하는 모델의 가중치를 찾는게 목적인 딥러닝에서\n",
    "#그 손실 함수의 기울기를 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8c9aa5b-6986-4964-82e5-e077794a394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.035052765160799026\n",
      "100 : 0.028888389468193054\n",
      "200 : 0.024857468903064728\n",
      "300 : 0.022346610203385353\n",
      "400 : 0.02077139914035797\n",
      "500 : 0.01971716247498989\n",
      "600 : 0.01899200677871704\n",
      "700 : 0.018494194373488426\n",
      "800 : 0.018152408301830292\n",
      "900 : 0.017906881868839264\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    outputs=model.forward(X_train_tensors_f)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, y_train_tensors)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"{epoch} : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf2056-9a28-450c-ae9d-6bca8b6941ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
